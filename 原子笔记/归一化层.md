归一化层（Normalization Layer）是深度学习中常用的一种神经网络层，其作用是对输入数据进行正则化处理，将其缩放到均值为0、方差为1的范围内。主要有以下几个作用：

加速训练收敛：由于归一化后的数据更加稳定，梯度的传递也变得更加平滑，使得模型的训练更加容易收敛。

提高模型精度：归一化可以消除数据间的偏差，并且有助于防止梯度消失或爆炸现象的出现，从而提高模型的精度。

增强模型的泛化能力：归一化对输入数据的分布没有任何要求，可以适用于不同的场景和数据集，因此能够增强模型的泛化能力。

总之，归一化层是一种非常有效的神经网络层，可以帮助我们提高模型的性能和鲁棒性。