> [!info] Bibliography
> [1]  WANG Q, DU J, BAO X, 等. A universal VAD based on jointly trained deep neural networks[C/OL]//Interspeech 2015. ISCA, 2015: 2282-2286[2023-07-23]. [https://www.isca-speech.org/archive/interspeech_2015/wang15e_interspeech.html](https://www.isca-speech.org/archive/interspeech_2015/wang15e_interspeech.html). DOI:[10.21437/Interspeech.2015-442](https://doi.org/10.21437/Interspeech.2015-442).
## Information

| Key          |                                   Value                                   |
| :----------- | :-----------------------------------------------------------------------: |
| Date         |                                      2015-09  |
| Author       |                         Qing Wang, Jun Du, Xiao Bao, Zi-Rui Wang, Li-Rong Dai, Chin-Hui Lee                          |
| Contributors |                                                           |
| Tags         |                           #知识/科研/VAD, #zotero, #文献笔记                         |
| Journal      |                            #              |
| DOI          |                            [10.21437/Interspeech.2015-442](https://www.isca-speech.org/archive/interspeech_2015/wang15e_interspeech.html)                             |
| Extra        |                                              |
| Type         |                            conferencePaper                           |
| Publisher    |                               ISCA                               |
| Others       |     DOI.org (Crossref)         |
| Zotero Link  |                             [Wang et al_2015_A universal VAD based on jointly trained deep neural networks.pdf](zotero://select/library/items/FPXXUMKC)                             |

> [!abstract]
> In this paper, we propose a **joint training approach** to voice activity detection (VAD) to **address** the issue of performance **degradation** due to unseen noise conditions. Two key techniques are **integrated** into this deep neural network (DNN) based VAD framework. First, a **regression** DNN is trained to map the noisy to clean speech features similar to DNN-based speech enhancement. Second, the VAD part to discriminate speech against noise backgrounds is also a DNN trained with a large amount of **diversiﬁed** noisy data **synthesized** by a wide range of additive noise types. By **stacking** the classiﬁcation DNN on top of the enhancement DNN, this integrated DNN can be jointly trained to perform VAD. The feature mapping DNN serves as a **noise normalization module** aiming at **explicitly** generating the **“clean” features** which are easier to be correctly recognized by the following classiﬁcation DNN. Our experiment results demonstrate the proposed **noise-universal** DNNbased VAD algorithm achieves a good **generalization capacity** to unseen noises, and the jointly trained DNNs **consistently** and **signiﬁcantly** outperform the conventional classiﬁcation-based DNN **for all the noise types** and signal-to-noise levels tested.

## Notes
%% begin Obsidian-Notes %%%% end Obsidian-Notes %%
![[Pasted image 20230731235751.png]]
[image] ([pdf](zotero://open-pdf/library/items/FPXXUMKC?page=2&annotation=L6T9AL2Q))  
([Wang 等, 2015, p. 2283](zotero://select/library/items/PG3J4LDS))
%% Import Date: 2023-07-31T22:54:46.506+08:00 %%
