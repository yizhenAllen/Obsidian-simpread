---
title: "A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code"
alias: 
  - "A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code"
created-date: 2023-04-09T20:54:16+0800
type: Simpread
banner: "https://production-media.paperswithcode.com/thumbnails/paper/2103.03529.jpg "
banner_icon: ğŸ”–
tag: 
idx: 32
---

# A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code

> [!example]- [ğŸ§·å†…éƒ¨é“¾æ¥](<http://localhost:7026/unread/32>) [ğŸŒå¤–éƒ¨é“¾æ¥](<https://paperswithcode.com/paper/a-hybrid-cnn-bilstm-voice-activity-detector>)    
> URI:: [ğŸ§·](<http://localhost:7026/unread/32>) [ğŸŒ](<https://paperswithcode.com/paper/a-hybrid-cnn-bilstm-voice-activity-detector>) 
> intURI:: [ğŸ§·å†…éƒ¨é“¾æ¥](<http://localhost:7026/reading/32>)

%%
> [!example]+ **Comments**  
> ```dataview
> TABLE 
>     WITHOUT ID
>     link(Source, dateformat(date(Source), "yyyy-MM-dd")) as Date___, 
>     regexreplace(rows.Comments,"^@@\[\[.+?\]\]\s","") as "Comments"
> FROM "journals"
> WHERE  contains(cmnt, this.file.name)
> FLATTEN cmnt as Comments
> WHERE contains(Comments, this.file.name)
> GROUP BY file.link as Source
> SORT rows.file.day desc
> ```
>  **Description**:: Implemented in one code library.
%%

> [!md] Metadata  
> **æ ‡é¢˜**:: [A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code](https://paperswithcode.com/paper/a-hybrid-cnn-bilstm-voice-activity-detector)  
> **æ—¥æœŸ**:: [[2023-04-09]]  

## Annotations


> [!srhl2] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #ffeb3b">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681044855330>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681044855330>)   
> incorporating both convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM) layers trained in an end-to-end manner.
> ^sran-1681044855330
 
> [!srhl4] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #a1e0ff">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681044868890>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681044868890>)   
> we focus specifically on optimising the computational efficiency of our architecture in order to deliver robust performance in difficult in-the-wild noise conditions in a severely under-resourced setting.
> ^sran-1681044868890
 
> [!srhl2] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #ffeb3b">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681044908050>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681044908050>)   
> Nested k-fold cross-validation was used to explore the hyperparameter space, and the trade-off between optimal parameters and model size is discussed.
> ^sran-1681044908050
 
> [!srhl4] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #a1e0ff">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681044950619>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681044950619>)   
> performance effect of a BiLSTM layer compared to a unidirectional LSTM layer was also considered
> ^sran-1681044950619
 
> [!srhl2] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #ffeb3b">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681045000626>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681045000626>)   
> We compare our systems with three established baselines on the AVA-Speech dataset.
> ^sran-1681045000626
 
> [!srhl5] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #a8ea68">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681045157698>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681045157698>)   
> BiLSTM layers were shown to improve accuracy over unidirectional layers by 2% absolute on average.
> ^sran-1681045157698
 
> [!srhl2] [[SR32@A Hybrid CNN-BiLSTM Voice Activity Detector _ Papers With Code|ğŸ“„]] <mark style="background-color: #ffeb3b">Highlights</mark> [ğŸ§·](<http://localhost:7026/unread/32#id=1681045176058>) [ğŸŒ](<http://localhost:7026/reading/32#id=1681045176058>)   
> outperforms all baselines, including a much larger ResNet system, particularly in difficult noise conditions.
> ^sran-1681045176058
 
 